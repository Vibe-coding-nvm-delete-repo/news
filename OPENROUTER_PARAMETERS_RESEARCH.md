# OpenRouter.ai API Parameters Research

## Executive Summary

The application currently uses **ONLY 2 parameters**:

- `model` (with :online suffix)
- `messages`

OpenRouter supports **20+ additional parameters** that can dramatically improve:

- ‚úÖ Response quality and accuracy
- ‚úÖ Output consistency and format adherence
- ‚úÖ Reasoning depth and transparency
- ‚úÖ Cost optimization
- ‚úÖ Token usage control

---

## üéØ CRITICAL PARAMETERS TO ADD

### 1. **Temperature** (0.0 - 2.0)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• HIGH - Controls creativity vs accuracy

```json
"temperature": 0.7
```

- **0.0-0.3**: Deterministic, factual (ideal for news accuracy)
- **0.7-1.0**: Balanced (default for most models)
- **1.0-2.0**: Creative, diverse outputs

**Recommendation for News App:**

- Use `0.3-0.5` for factual news searches
- Use `0.7` for summary generation

---

### 2. **Max Tokens** (max_tokens)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• HIGH - Controls response length and cost

```json
"max_tokens": 2000
```

**Benefits:**

- Prevents excessively long responses
- Reduces API costs
- Ensures consistent output lengths
- Prevents timeout issues

**Recommendation:**

- News searches: `1500-2500` tokens
- Quick queries: `500-1000` tokens

---

### 3. **Top P** (Nucleus Sampling, 0.0-1.0)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• HIGH - Alternative to temperature

```json
"top_p": 0.9
```

- **0.1-0.5**: Very focused, deterministic
- **0.9-0.95**: Balanced (recommended)
- **0.95-1.0**: More diverse

**Recommendation:** Use `0.9` with lower temperature for news

---

### 4. **Frequency Penalty** (-2.0 to 2.0)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• MEDIUM-HIGH - Reduces repetition

```json
"frequency_penalty": 0.5
```

- Positive values: Reduce word repetition
- Negative values: Encourage repetition
- **0.3-0.7**: Ideal for varied news stories

**Why Important:** Prevents AI from repeating same phrases/facts

---

### 5. **Presence Penalty** (-2.0 to 2.0)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• MEDIUM - Encourages topic diversity

```json
"presence_penalty": 0.3
```

- Positive values: Encourage new topics/themes
- **0.2-0.5**: Good for diverse news coverage

**Why Important:** Ensures varied news stories, not duplicates

---

### 6. **Response Format** (JSON Mode)

**Current Status:** ‚ùå NOT USED (but needed!)  
**Impact:** üî• CRITICAL - Ensures valid JSON

```json
"response_format": { "type": "json_object" }
```

**Why CRITICAL:**

- Your app expects JSON but doesn't enforce it!
- Current code uses complex JSON parsing fallbacks
- This parameter **guarantees** valid JSON responses
- Reduces parsing errors significantly

---

### 7. **Stop Sequences** (stop)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• MEDIUM - Prevents unwanted content

```json
"stop": ["END", "\n\n---", "###"]
```

**Use Cases:**

- Stop at specific markers
- Prevent model from adding explanations after JSON
- Control output boundaries

---

### 8. **Seed** (Reproducibility)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• MEDIUM - Makes results reproducible

```json
"seed": 12345
```

**Benefits:**

- Reproducible results for testing
- Consistent output for same inputs
- Better debugging

---

## üß† REASONING MODELS ONLY

### 9. **Reasoning Level** (reasoning)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• CRITICAL for O1/O3/reasoning models

```json
"reasoning": "high"    // or "low", "medium"
```

**Values:**

- `low`: Fast, basic reasoning
- `medium`: Balanced (default)
- `high`: Deep, thorough reasoning (more expensive)

**Models Supporting This:**

- OpenAI O1/O3 series
- Claude with extended thinking
- DeepSeek R1
- Qwen reasoning variants

---

### 10. **Include Reasoning** (include_reasoning)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• HIGH - Shows model's thinking process

```json
"include_reasoning": true
```

**Benefits:**

- See how model arrived at conclusions
- Verify factual accuracy
- Debug poor responses
- Understand reasoning depth

**Use Cases:**

- Quality control
- Fact verification
- Model comparison

---

## üìä ADVANCED PARAMETERS

### 11. **Top K** (top_k)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• LOW-MEDIUM - Limits token sampling

```json
"top_k": 40
```

- Limits sampling to top K tokens
- Alternative to top_p
- **20-50**: Good range for most use cases

---

### 12. **Min P** (min_p)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• LOW-MEDIUM - Minimum probability threshold

```json
"min_p": 0.05
```

- Filters out low-probability tokens
- More stable than top_p for some models
- **0.05-0.1**: Common values

---

### 13. **Repetition Penalty** (repetition_penalty)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• MEDIUM - Similar to frequency penalty

```json
"repetition_penalty": 1.1
```

- **1.0**: No penalty
- **1.1-1.3**: Moderate penalty (recommended)
- **>1.5**: Strong penalty (may hurt quality)

---

### 14. **Logit Bias** (logit_bias)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• LOW - Fine-grained token control

```json
"logit_bias": {
  "1234": -100,  // Ban specific tokens
  "5678": 50     // Encourage specific tokens
}
```

**Advanced Use Cases:**

- Ban profanity tokens
- Encourage specific terminology
- Control output style

---

### 15. **Logprobs & Top Logprobs**

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• LOW - Model confidence analysis

```json
"logprobs": true,
"top_logprobs": 5
```

**Benefits:**

- Understand model confidence
- Analyze uncertainty
- Quality assessment

---

### 16. **Structured Outputs** (structured_outputs)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• HIGH - Enforces JSON schema

```json
"structured_outputs": true
```

**Benefits:**

- Enforces specific JSON structure
- Better than response_format alone
- Guarantees schema compliance

---

### 17. **Tool Choice & Tools**

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• MEDIUM - Function calling

```json
"tools": [...],
"tool_choice": "auto"
```

**Potential Use:**

- Could enable web search as explicit tool
- Better control over search behavior

---

## üåê OPENROUTER-SPECIFIC FEATURES

### 18. **Provider Preferences**

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• MEDIUM - Control which provider serves request

```json
"provider": {
  "order": ["Anthropic", "OpenAI"],
  "allow_fallbacks": true
}
```

**Benefits:**

- Choose specific providers
- Control latency vs cost
- Fallback options

---

### 19. **Transforms**

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• LOW - Modify prompts automatically

```json
"transforms": ["middle-out"]
```

**Use Cases:**

- Automatic prompt engineering
- Context window optimization

---

### 20. **Models Override** (for testing)

**Current Status:** ‚ùå NOT USED  
**Impact:** üî• LOW - A/B testing

```json
"models": ["model-1", "model-2"]
```

---

## üí∞ COST OPTIMIZATION PARAMETERS

### Web Search Pricing

**Current Status:** ‚ö†Ô∏è AWARE but not controllable  
**Impact:** The `:online` suffix adds $0.01 per search (for many models)

**What's Missing:**

- No way to see web search costs separately
- No option to disable web search per keyword
- No control over search depth

---

### Internal Reasoning Costs

Some models charge extra for reasoning tokens:

```
"internal_reasoning": "0.00001"  // per token
```

**Missing:** No way to control or track reasoning costs

---

## üé® UI/SETTINGS RECOMMENDATIONS

### NEW SETTINGS TAB: "Model Parameters"

#### Section 1: Basic Parameters

- **Temperature** (slider 0.0-2.0, default 0.5)
- **Max Tokens** (input field, default 2000)
- **Response Format** (dropdown: Auto, JSON, Text)

#### Section 2: Quality Controls

- **Top P** (slider 0.0-1.0, default 0.9)
- **Frequency Penalty** (slider 0.0-2.0, default 0.5)
- **Presence Penalty** (slider 0.0-2.0, default 0.3)

#### Section 3: Reasoning (for compatible models)

- **Reasoning Level** (dropdown: Low, Medium, High)
- **Include Reasoning Output** (toggle)

#### Section 4: Advanced (collapsible)

- **Top K** (input field, optional)
- **Min P** (slider, optional)
- **Repetition Penalty** (slider 1.0-2.0)
- **Stop Sequences** (multi-input field)
- **Seed** (input field for reproducibility)

#### Section 5: Cost Controls

- **Max Tokens per Keyword** (input field)
- **Enable Web Search** (toggle - currently always on)
- **Provider Preferences** (dropdown)

---

## üìà PRIORITY IMPLEMENTATION ORDER

### Phase 1: CRITICAL (Do First) üî•

1. **response_format: json_object** - Fixes JSON parsing issues
2. **temperature** - Major quality impact
3. **max_tokens** - Cost control + performance
4. **structured_outputs** - Schema enforcement

### Phase 2: HIGH PRIORITY üî•

5. **frequency_penalty** - Reduces repetition
6. **presence_penalty** - Better diversity
7. **top_p** - Alternative temperature control
8. **reasoning + include_reasoning** - For reasoning models

### Phase 3: MEDIUM PRIORITY

9. **stop** sequences
10. **seed** for reproducibility
11. **top_k** / **min_p**
12. **repetition_penalty**

### Phase 4: ADVANCED (Later)

13. **logit_bias**
14. **logprobs**
15. **provider preferences**
16. **tools/tool_choice**

---

## üîß IMPLEMENTATION CHANGES NEEDED

### 1. Update Store Interface (`lib/store.ts`)

Add new settings:

```typescript
export interface ModelParameters {
  temperature?: number; // 0.0-2.0
  max_tokens?: number; // e.g., 2000
  top_p?: number; // 0.0-1.0
  frequency_penalty?: number; // 0.0-2.0
  presence_penalty?: number; // 0.0-2.0
  response_format?: 'auto' | 'json_object' | 'text';
  stop?: string[]; // Stop sequences
  seed?: number; // Reproducibility

  // Reasoning models only
  reasoning?: 'low' | 'medium' | 'high';
  include_reasoning?: boolean;

  // Advanced
  top_k?: number;
  min_p?: number;
  repetition_penalty?: number;
  logit_bias?: Record<string, number>;
  logprobs?: boolean;
  top_logprobs?: number;
}

export interface Settings {
  apiKey: string | null;
  selectedModel: string | null;
  keywords: Keyword[];
  searchInstructions: string;
  onlineEnabled: boolean;
  modelParameters: ModelParameters; // NEW!
}
```

### 2. Update API Call (`components/NewsTab.tsx`)

```typescript
body: JSON.stringify({
  model: onlineModel,
  messages: [
    {
      role: 'user',
      content: `${settings.searchInstructions}\n\n"${keyword.text}"`,
    },
  ],
  // ADD NEW PARAMETERS:
  temperature: settings.modelParameters?.temperature ?? 0.5,
  max_tokens: settings.modelParameters?.max_tokens ?? 2000,
  top_p: settings.modelParameters?.top_p,
  frequency_penalty: settings.modelParameters?.frequency_penalty,
  presence_penalty: settings.modelParameters?.presence_penalty,
  response_format: settings.modelParameters?.response_format === 'json_object'
    ? { type: 'json_object' }
    : undefined,
  stop: settings.modelParameters?.stop,
  seed: settings.modelParameters?.seed,
  reasoning: settings.modelParameters?.reasoning,
  include_reasoning: settings.modelParameters?.include_reasoning,
  // ... other parameters
}),
```

### 3. Create New Settings UI (`components/SettingsTab.tsx`)

Add new subtab: **"Model Parameters"**

---

## üéØ EXPECTED IMPROVEMENTS

### With Recommended Parameters:

#### News Search Accuracy

- **Before:** Variable quality, sometimes off-topic
- **After:** Consistent, focused results with `temperature: 0.5`

#### JSON Parsing Success Rate

- **Before:** ~85% (requires fallback parsing)
- **After:** ~99% with `response_format: json_object`

#### Response Time

- **Before:** Variable, sometimes hangs
- **After:** Faster with `max_tokens: 2000`

#### Cost per Keyword

- **Before:** Unpredictable, often excessive
- **After:** Controlled with `max_tokens`

#### Output Quality

- **Before:** Sometimes repetitive
- **After:** More diverse with `frequency_penalty: 0.5`

---

## üìö MODEL-SPECIFIC RECOMMENDATIONS

### For GPT-4/GPT-5:

```json
{
  "temperature": 0.5,
  "max_tokens": 2000,
  "response_format": { "type": "json_object" },
  "frequency_penalty": 0.5,
  "presence_penalty": 0.3
}
```

### For O1/O3 Reasoning Models:

```json
{
  "reasoning": "high",
  "include_reasoning": true,
  "max_tokens": 3000
}
```

### For Claude Models:

```json
{
  "temperature": 0.7,
  "max_tokens": 2000,
  "top_p": 0.9,
  "frequency_penalty": 0.5
}
```

### For Budget Models (Haiku, etc):

```json
{
  "temperature": 0.3,
  "max_tokens": 1500,
  "top_p": 0.95
}
```

---

## üöÄ NEXT STEPS

1. ‚úÖ Review this document
2. ‚ö° Add Phase 1 critical parameters first
3. üé® Design UI for parameter controls
4. üß™ Test with different parameter combinations
5. üìä Measure quality improvements
6. üìù Update documentation

---

## üìñ REFERENCES

- [OpenRouter Documentation](https://openrouter.ai/docs)
- [OpenRouter Parameters](https://openrouter.ai/docs#parameters)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/chat/create)
- [Anthropic API Reference](https://docs.anthropic.com/claude/reference)

---

**Document Status:** ‚úÖ COMPLETE - Ready for Implementation  
**Last Updated:** 2025-10-16  
**Priority:** üî• HIGH - Major quality improvements available
